{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_idf = pd.read_csv(\"state-of-the-union.csv\",low_memory=False,names=[\"text\", \"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows,columns= (167814, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows,columns= (167814, 10)\n"
     ]
    }
   ],
   "source": [
    "df_idf = df_idf.replace('NaN', 0)\n",
    "print(\"Number of rows,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text  \\\n",
      "75363                 it difficult and complicated duties   \n",
      "81657   confidence of the victim into an opportunity t...   \n",
      "129813  agricultural crop. It will place every produce...   \n",
      "69866   general an introduction of this feature of mai...   \n",
      "117444                                           business   \n",
      "...                                                   ...   \n",
      "98033   was promptly recognized by the Government of t...   \n",
      "121016                                    Nation's needs.   \n",
      "110288  The necessary statistics are now being gathere...   \n",
      "40425                              grades in the service.   \n",
      "90309                        who commit the crime of rape   \n",
      "\n",
      "                                              B  \\\n",
      "75363        and requires the exaction from the   \n",
      "81657                                       NaN   \n",
      "129813                                      NaN   \n",
      "69866                                       NaN   \n",
      "117444                 to which I have referred   \n",
      "...                                         ...   \n",
      "98033                                       NaN   \n",
      "121016                                      NaN   \n",
      "110288                                      NaN   \n",
      "40425                                       NaN   \n",
      "90309    are in the great majority men who have   \n",
      "\n",
      "                                               C    D    E    F    G    H  \\\n",
      "75363                                        NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "81657                                        NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "129813                                       NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "69866                                        NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "117444   it seems clear to me that existing laws  NaN  NaN  NaN  NaN  NaN   \n",
      "...                                          ...  ...  ...  ...  ...  ...   \n",
      "98033                                        NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "121016                                       NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "110288                                       NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "40425                                        NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "90309                                        NaN  NaN  NaN  NaN  NaN  NaN   \n",
      "\n",
      "          I    J  \n",
      "75363   NaN  NaN  \n",
      "81657   NaN  NaN  \n",
      "129813  NaN  NaN  \n",
      "69866   NaN  NaN  \n",
      "117444  NaN  NaN  \n",
      "...     ...  ...  \n",
      "98033   NaN  NaN  \n",
      "121016  NaN  NaN  \n",
      "110288  NaN  NaN  \n",
      "40425   NaN  NaN  \n",
      "90309   NaN  NaN  \n",
      "\n",
      "[100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    " print(df_idf.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf = df_idf.drop(['B','C','D','E','F','G','H','I','J'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "\n",
      " text    object\n",
      "dtype: object\n",
      "Number of rows,columns= (167814, 1)\n"
     ]
    }
   ],
   "source": [
    "# print schema\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of rows,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text\n",
      "149792                                                NaN\n",
      "115950  relationship that we have shared during these ...\n",
      "70051   related to a sacred duty of the Government and...\n",
      "157521                             For the last two years\n",
      "41539               beyond that period? Our abundant room\n",
      "52745   and of such as may hereafter arise. While by e...\n",
      "114136  directed the temporary transfer of the Army Di...\n",
      "10269                                                 NaN\n",
      "35082   From this statement it is easy to account for ...\n",
      "99614                                                 NaN\n"
     ]
    }
   ],
   "source": [
    "print(df_idf.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf = df_idf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text\n",
      "41752   trust that in view of the great responsibility...\n",
      "83216   their allotments. The effort should be steadil...\n",
      "13863   themselves from the injurious effects of a sup...\n",
      "90946   have the same chance to rise and develop as ot...\n",
      "100917  admirals under his orders. This is not as it s...\n",
      "103395  exhibition and protect foreign exhibitors agai...\n",
      "20993                                            the same\n",
      "102850  the conduct of his department have proven to b...\n",
      "151965  never again permit wild currency swings to cri...\n",
      "91506                 Republics of the southern continent\n"
     ]
    }
   ],
   "source": [
    "print(df_idf.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"<!--?.*?-->\",\"\",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text\n",
      "90395   instincts and passions in order to arouse one ...\n",
      "42119   Navy in regard to the policy of fostering and ...\n",
      "126179  can get a good idea of how much our country sh...\n",
      "94214   power has prepared best in time of peace. The ...\n",
      "64601                                      Samoan Islands\n",
      "93740                                                mice\n",
      "29689   agents among these tribes in all treaties to m...\n",
      "20225                                     a barbarous age\n",
      "44126   and industry. It would alleviate the present t...\n",
      "147115  The talents of women should continue to be use...\n"
     ]
    }
   ],
   "source": [
    "print(df_idf.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text\n",
      "78727   commissioners proposed that the subject of the...\n",
      "101411  republics for the purpose of giving evidence o...\n",
      "99713                                   britain of april \n",
      "98654   in may last the supreme court handed down deci...\n",
      "10623                                         authorities\n",
      "34693   france having consented to observe them for th...\n",
      "101303  administration to demand for american citizens...\n",
      "89807   which converted the island of cuba from a pest...\n",
      "13515   in the question could be obtained to this prop...\n",
      "98716   terms of the statute this is wholly untrue a r...\n"
     ]
    }
   ],
   "source": [
    "#show the second 'text' just for fun\n",
    "print(df_idf.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "\n",
      " text    object\n",
      "dtype: object\n",
      "Number of rowss,columns= (147710, 1)\n"
     ]
    }
   ],
   "source": [
    "# print schema\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of rowss,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    " \n",
    "#load a set of stop words\n",
    "stopwords='english'\n",
    " \n",
    "#get the text column \n",
    "docs=df_idf['text'].tolist()\n",
    " \n",
    "#create a vocabulary of words, \n",
    "#ignore words that appear in 85% of documents, \n",
    "#eliminate stop words\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147710, 20669)\n"
     ]
    }
   ],
   "source": [
    "print(word_count_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147710, 20000)\n"
     ]
    }
   ],
   "source": [
    "#Let's limit our vocabulary size to 20,000\n",
    "cv=CountVectorizer(max_df=0.85,stop_words=stopwords,max_features=20000)\n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "print(word_count_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protection',\n",
       " 'important',\n",
       " 'interests',\n",
       " 'citizens',\n",
       " 'engaged',\n",
       " 'commerce',\n",
       " 'fisheries',\n",
       " 'sea',\n",
       " 'vessels',\n",
       " 'likewise']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cv.vocabulary_.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blackburn',\n",
       " 'blacken',\n",
       " 'blacker',\n",
       " 'blackford',\n",
       " 'blackmail',\n",
       " 'blackmailed',\n",
       " 'blackouts',\n",
       " 'blacks',\n",
       " 'blacksmith',\n",
       " 'blacksmiths',\n",
       " 'blackwell',\n",
       " 'blaine',\n",
       " 'blair',\n",
       " 'blake',\n",
       " 'blamable']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the vocabulary by using get_feature_names() only for testing purpose\n",
    "list(cv.get_feature_names())[2000:2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfTransformer to Compute Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.20986576 12.20986576 12.20986576 ... 12.20986576 12.20986576\n",
      " 11.29357503]\n"
     ]
    }
   ],
   "source": [
    "#some of the IDF values:\n",
    "print(tfidf_transformer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test docs into a list I could not find out sample text of 1900 decade\n",
    "docs_test=df_idf['text'].tolist()[2000:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "\n",
    "    for idx, score in sorted_items:\n",
    "        fname = feature_names[idx]\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only needs to do this once\n",
    "feature_names=cv.get_feature_names()\n",
    "\n",
    "# get the document that we want to extract keywords from\n",
    "doc=docs_test[250]\n",
    "\n",
    "#generate tf-idf for the given document\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "\n",
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==Keywords===\n",
      "\n",
      "probable 0.456\n",
      "extensive 0.427\n",
      "society 0.409\n",
      "human 0.375\n",
      "condition 0.331\n",
      "commerce 0.328\n",
      "present 0.291\n"
     ]
    }
   ],
   "source": [
    "# now print the results\n",
    "print(\"\\n==Keywords===\\n\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the common code into several methods\n",
    "def get_keywords(idx):\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector=tfidf_transformer.transform(cv.transform([docs_test[idx]]))\n",
    "\n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only the top n; n here is 10\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "def print_results(idx,keywords):\n",
    "    # now print the results\n",
    "    print(\"\\n=====Title=====\")\n",
    "    print(docs_title[idx])\n",
    "    print(\"\\n=====Body=====\")\n",
    "    print(docs_body[idx])\n",
    "    print(\"\\n===Keywords===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
